getwd()
usethis::edit_r_profile()
usethis
usethis::edit_r_environ()
getwd()
.libPaths()
5+6
install.packages("xfun")
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE)
library(dagitty)
library(tidyverse)
library(latex2exp)
library(actufair)
#source("fonctions_mediator.R")
library(dagitty)
dags <- list(dag_med = dagitty('dag {
D [pos="-1.410,-0.804"]
Y [outcome,pos="-0.216,0.560"]
X [exposure,pos="-1.582,0.307"]
D -> Y
X -> Y
X -> D
}
'),
dag_conf = dagitty('dag {
D [pos="-1.410,-0.804"]
Y [outcome,pos="-0.216,0.560"]
X [exposure,pos="-1.582,0.307"]
X -> Y
D -> X
D -> Y
}
')
)
plot(dags$dag_med)
plot(dags$dag_conf)
get_adjmat_from_DAG(dags$dag_med)
get_adjmat_from_DAG(dags$dag_conf)
get_DAG_from_adjmat(get_adjmat_from_DAG(dags$dag_med)) %>% plot
list_seq <- list("X" = function(n, table, anc = get_required_anc("X", L)){
rnorm(n, 5 + 7 * table[, anc], 3)
},
"D" = function(n, table, anc = get_required_anc("D", L)){
rbinom(n, size = 3, prob = 2/3)
},
"Y" = function(n, table, anc = get_required_anc("Y", L)){
mu <- 100 + 5 * table[, anc[1]] * table[, anc[2]]
alpha <- 10
beta <- alpha/mu
rgamma(n, shape = alpha, rate = beta)
})
train <- simul_algo1_gen(dag = dags$dag_conf,
n = 1e4,
list_sim_fun = list_seq)
summary(train$sims)
# test$iterations
(lm(X ~ D, data = train$sims) %>%  summary(.))$coefficients
(glm(Y ~ X + D + X*D,
data = train$sims,
family = Gamma(link = "identity")) %>%
summary(.))$coefficients
train$sims %>%  ggplot(aes(x = factor(D), color = factor(D), fill = factor(D))) +
geom_bar(alpha= 0.25) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = X)) +
geom_histogram(alpha= 0.5) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = Y)) +
geom_histogram(alpha= 0.5) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = factor(D), y = X, color = factor(D), fill = factor(D))) +
geom_boxplot(alpha= 0.25) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = X, color = factor(D), fill = factor(D))) +
geom_histogram(position = "dodge", alpha= 0.25) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = X, y = Y)) +
geom_point(size= 2, alpha= 0.05) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = factor(D), y = Y, color = factor(D), fill = factor(D))) +
geom_boxplot(alpha= 0.25) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = Y, color = factor(D), fill = factor(D))) +
geom_histogram(position = "dodge", alpha= 0.25) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
train$sims %>%  ggplot(aes(x = X, y = Y, fill = factor(D), color = factor(D))) +
geom_point(size= 2, alpha= 0.05) +
scale_fill_brewer(palette = "Dark2") +
scale_color_brewer(palette = "Dark2") +
theme_bw()
glm_full <- glm(Y ~ X + D, #+ X*D, The model does not spot the interaction
data = train$sims,
family = Gamma(link = "log"))
glm_ign <- glm(Y ~ X,
data = train$sims,
family = Gamma(link = "log"))
library(lightgbm)
library(tictoc)
nthreads.olico <- parallel::detectCores(all.tests = FALSE,
logical = TRUE)
file_name_full <- "models/lgb_full_001"
if(file.exists(file_name_full)){
lgb_full <- lgb.load("models/lgb_full_001")
} else {
## On peut traiter les variables catégorielles pour `lightgbm`
train_prepared_lgb_full <- lgb.convert_with_rules(train$sims %>% select(-Y))
saveRDS(train_prepared_lgb_full, "data/train_prepared_lgb_full_001")
## On créé la lgb.Matrix
categ_fet <- sapply(names(train_prepared_lgb_full$rules),
function (n) which(n == names(train_prepared_lgb_full$data)))
categ_fet2 <- categ_fet
if(length(categ_fet) == 0) categ_fet2 <- NULL
## On créé la lgb.Matrix
train_lgb_full <- lgb.Dataset(as.matrix(train_prepared_lgb_full$data),
categorical_feature = categ_fet2,
label = train$sims$Y)
## parameters
parameters <- list(max_depth = 6, # interaction depth + 1
min_data_in_leaf = floor(0.75*0.01*nrow(train)),
seed = 42,
learning_rate = 0.01,
bagging_fraction = 0.75,
objective = "gamma")
## optimal number of trees
lgb_cv_full <- lgb.cv(train_lgb_full,
nrounds = 2000,
params = parameters,
num_threads = nthreads.olico,
nfold = 5)
# > lgb_cv_full$best_iter
# [1] 1909
## training
tic("LGBM full")
lgb_full <- lightgbm(train_lgb_full,
nrounds = lgb_cv_full$best_iter,
params = parameters,
num_threads = nthreads.olico)
toc_lgb_full <- toc()
lgb.save(lgb_full, "models/lgb_full_001")
}
predict_lgb <- function(data,
model = "full",
version = "001"){
### FULL test
train_prepared_lgb <- readRDS(paste0("data/train_prepared_lgb_", model, "_", version))
test_prepared <- lgb.convert_with_rules(data,
rules = train_prepared_lgb$rules)
lgb <- lgb.load(paste0("models/lgb_", model, "_", version))
pred_lgb_full <- predict(lgb, data = as.matrix(test_prepared$data))
return(pred_lgb_full)
}
file_name_ign <- "models/lgb_ign_001"
if(file.exists(file_name_ign)){
lgb_ign <- lgb.load("models/lgb_ign_001")
} else {
## On peut traiter les variables catégorielles pour `lightgbm`
train_prepared_lgb_ign <- lgb.convert_with_rules(train$sims %>% select(-Y, -D))
saveRDS(train_prepared_lgb_ign, "data/train_prepared_lgb_ign_001")
## On créé la lgb.Matrix
categ_fet <- sapply(names(train_prepared_lgb_ign$rules),
function (n) which(n == names(train_prepared_lgb_ign$data)))
categ_fet2 <- categ_fet
if(length(categ_fet) == 0) categ_fet2 <- NULL
## On créé la lgb.Matrix
train_lgb_ign <- lgb.Dataset(as.matrix(train_prepared_lgb_ign$data),
categorical_feature = categ_fet2,
label = train$sims$Y)
## parameters
parameters <- list(max_depth = 6, # interaction depth + 1
min_data_in_leaf = floor(0.75*0.01*nrow(train)),
seed = 42,
learning_rate = 0.01,
bagging_fraction = 0.75,
objective = "gamma")
## optimal number of trees
lgb_cv_ign <- lgb.cv(train_lgb_ign,
nrounds = 2000,
params = parameters,
num_threads = nthreads.olico,
nfold = 5)
# > lgb_cv_ign$best_iter
# [1] 1909
## training
tic("LGBM ign")
lgb_ign <- lightgbm(train_lgb_ign,
nrounds = lgb_cv_ign$best_iter,
params = parameters,
num_threads = nthreads.olico)
toc_lgb_ign <- toc()
lgb.save(lgb_ign, "models/lgb_ign_001")
}
test <- simul_algo1_gen(dag = dags$dag_conf,
list_sim_fun = list_seq,
n = 2.5e3)
pred_glm_full <- predict(glm_full, newdata = test$sims, type = "response")
pred_lgb_full <- predict_lgb(data = test$sims %>% select(-Y),
model = "full")
pred_glm_ign <- predict(glm_ign, newdata = test$sims, type = "response")
pred_lgb_ign <- predict_lgb(data = test$sims %>% select(-D, -Y),
model = "ign")
table_D <- table(train$sims$D)
D_dist <- prop.table(table_D)
values_D <- names(table_D)
table_glm_preds <- values_D %>% sapply(function(v){
predict(glm_full, newdata = test$sims %>% mutate(D = rep(as.numeric(v), nrow(test$sims))), type = "response")
})
pred_glm_conf <- apply(table_glm_preds, 1, function(p) sum(p * D_dist))
table_lgb_preds <- values_D %>% sapply(function(v){
predict_lgb(data = test$sims %>% mutate(D = rep(as.numeric(v), nrow(test$sims))) %>%
select(-Y),
model = "full")
})
pred_lgb_conf <- apply(table_lgb_preds, 1, function(p) sum(p * D_dist))
library(nnet)
glm_med <- multinom(D ~ X,
data= train$sims)
file_name_class <- "models/lgb_class_001"
if(file.exists(file_name_class)){
lgb_class <- lgb.load("models/lgb_class_001")
} else {
## On peut traiter les variables catégorielles pour `lightgbm`
train_prepared_lgb_class <- lgb.convert_with_rules(train$sims %>% select(-Y, -D))
saveRDS(train_prepared_lgb_class, "data/train_prepared_lgb_class_001")
## On créé la lgb.Matrix
categ_fet <- sapply(names(train_prepared_lgb_class$rules),
function (n) which(n == names(train_prepared_lgb_class$data)))
categ_fet2 <- categ_fet
if(length(categ_fet) == 0) categ_fet2 <- NULL
## On créé la lgb.Matrix
train_lgb_class <- lgb.Dataset(as.matrix(train_prepared_lgb_class$data),
categorical_feature = categ_fet2,
label = train$sims$D)
## parameters
parameters <- list(max_depth = 6, # interaction depth + 1
min_data_in_leaf = floor(0.75*0.01*nrow(train)),
seed = 42,
learning_rate = 0.01,
bagging_fraction = 0.75,
objective = "multiclass",
num_class = 4)
## optimal number of trees
lgb_cv_class <- lgb.cv(train_lgb_class,
nrounds = 900,
params = parameters,
num_threads = nthreads.olico,
nfold = 5)
# > lgb_cv_class$best_iter
# [1] 1909
## training
tic("LGBM class")
lgb_class <- lightgbm(train_lgb_class,
nrounds = lgb_cv_class$best_iter,
params = parameters,
num_threads = nthreads.olico)
toc_lgb_class <- toc()
lgb.save(lgb_class, "models/lgb_class_001")
}
get_table_probs <- function(data, varname = "X", x,
model = "glm"){
## Modify the dataset
data[[varname]] <- rep(x, nrow(test$sims))
if(model == "glm"){
p <- predict(glm_med,
newdata = data,
type = "probs")
} else {
p <- predict_lgb(data = data %>% select(-D, -Y),
model = "class") %>%
matrix(ncol = 4, byrow = TRUE)
}
## return preds
return(
p
)
}
adjust_med_int <- function(preds_table, weight_table){
ids <- 1:nrow(preds_table)
return(
ids %>% sapply(function(i){
sum(preds_table[i, ] * weight_table[i, ])
})
)
}
summary(train$sims$X)
hist(train$sims$X)
pX <- function(x){
mix_probs <- dbinom(0:3, size = 3, prob = 2/3)
repart <- pnorm(x, mean = 5 + 7 * 0:3, 3)
sum(repart * mix_probs)
}
(minx <- optimize(function(x) log(abs(pX(x) - 0.0001)), interval = c(-50, 50))$minimum)
pX(minx)
(maxx <- optimize(function(x) log(abs(pX(x) - 0.9999)), interval = c(minx, 50))$minimum)
pX(maxx)
dX <- function(h, xmin, xmax, lower = TRUE){
x <- seq(floor(xmin), ceiling(xmax), by = h)
px <- x %>%  sapply(pX)
if(lower){
dx <- c(px[1],
tail(px, -1) - head(px, -1))
dx[length(x)] <- 1 - px[length(x) - 1]
} else {
dx <- c(head(1 - px, -1) - tail(1 - px, -1), 1 - px[length(x)])
dx[1] <- px[2]
}
return(
list("x" = x,
"dx" = dx)
)
}
dist_x <- dX(1, xmin = minx, xmax = maxx)
plot(dist_x$x, dist_x$dx) %>%  print
dist_x$dx %>% sum
adjust_med <- function(data,
preds_table,
fun_table_prob_M = get_table_probs,
model = "glm",
P_X,
values_X){
partial_exp <- values_X %>% sapply(function(xi){
adjust_med_int(preds_table = preds_table,
weight_table = fun_table_prob_M(data,
x = xi, model = model))
})
return(
apply(partial_exp, 1, function(e) sum(e * P_X))
)
}
# adjust_med_int(preds_table = table_glm_preds,
#                weight_table = get_table_probs(data = test$sims, x = dist_x$x[16])) %>% hist
pred_glm_med <- adjust_med(data = test$sims,
preds_table = table_glm_preds,
P_X = dist_x$dx,
values_X = dist_x$x)
pred_lgb_med <- adjust_med(data = test$sims,
preds_table = table_lgb_preds,
P_X = dist_x$dx,
model = "lgb",
values_X = dist_x$x)
summary(pred_glm_med)
summary(pred_lgb_med)
preds <- data.frame("full" = c(pred_glm_full * sum(test$sims$Y)/sum(pred_glm_full),
pred_lgb_full * sum(test$sims$Y)/sum(pred_lgb_full)),
"ign" = c(pred_glm_ign * sum(test$sims$Y)/sum(pred_glm_ign),
pred_glm_ign * sum(test$sims$Y)/sum(pred_glm_ign)),
"conf" = c(pred_glm_conf * sum(test$sims$Y)/sum(pred_glm_conf),
pred_glm_conf * sum(test$sims$Y)/sum(pred_glm_conf)),
"med" = c(pred_glm_med * sum(test$sims$Y)/sum(pred_glm_med),
pred_glm_med * sum(test$sims$Y)/sum(pred_glm_med)),
"model" = c(rep("glm", nrow(test$sims)),
rep("lgb", nrow(test$sims))),
rbind(test$sims, test$sims))
comp_preds <- function(data, sens, var1, var2){
to_g <- data.frame("p1" = data %>% pull(var1),
"p2"= data %>% pull(var2),
"d" = data %>% pull(sens))
to_g %>%  ggplot(aes(x = p1, y = p2, fill = factor(d),
color = factor(d))) +
geom_point(alpha = 0.05) +
theme_bw() +
scale_color_brewer(palette = "Dark2", name = sens) +
scale_fill_brewer(palette = "Dark2", name = sens) +
scale_x_continuous(labels = scales::dollar) +
scale_y_continuous(labels = scales::dollar) +
labs(y = paste0("Prediction ", var2),
x = paste0("Prediction ", var1),
title = paste0("Comparaison des predictions ",
var1, " et ", var2))+
geom_abline(intercept = 0, slope = 1, color="black",
linetype="dashed", size=0.4, alpha = 0.5) +
geom_smooth(lwd = 0.4)
}
library(plotly)
comp_preds(preds %>% filter(model == "glm"), sens= "D", var1 = "full", var2 = "ign")
comp_preds(preds %>% filter(model == "lgb"), sens= "D", var1 = "full", var2 = "ign")
comp_preds(preds %>% filter(model == "glm"), sens= "D", var1 = "full", var2 = "conf")
comp_preds(preds %>% filter(model == "lgb"), sens= "D", var1 = "full", var2 = "conf")
comp_preds(preds %>% filter(model == "glm"), sens= "D", var1 = "full", var2 = "med")
comp_preds(preds %>% filter(model == "lgb"), sens= "D", var1 = "full", var2 = "med")
comp_preds(preds %>% filter(model == "glm"), sens= "D", var1 = "ign", var2 = "conf")
comp_preds(preds %>% filter(model == "lgb"), sens= "D", var1 = "ign", var2 = "conf")
comp_preds(preds %>% filter(model == "glm"), sens= "D", var1 = "ign", var2 = "med")
comp_preds(preds %>% filter(model == "lgb"), sens= "D", var1 = "ign", var2 = "med")
comp_preds(preds %>% filter(model == "glm"), sens= "D", var1 = "conf", var2 = "med")
comp_preds(preds %>% filter(model == "lgb"), sens= "D", var1 = "conf", var2 = "med")
summary(preds$med - preds$conf)
# devtools::install_github("olicoside/actufair",
#                          auth_token = "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",
#                          force = TRUE)
#devtools::install_github("olicoside/actuarialmetrics")
library(actuarialmetrics)
table_to_g <- get_lr_table(preds %>%
mutate(n = 1) %>%
filter(model == "lgb"),
ref_name = "ign",
comp_name = "conf",
expo_name = "n",
loss_name = "Y",
n_cuts = 6)
dbl_lift_chart(table_to_g)
lrlift_graph(table_to_g)
pred_table <- preds %>% filter(model == "lgb") %>% select(full, ign, conf, Y)
names(pred_table) <- c("mod1", "mod2", "mod3", "y")
setwd()
getwd()
setwd("C:/Users/olico/ulaval/Rpackages")
setwd("C:/Users/olico/ulaval/Rpackages/actuarialmetrics/")
usethis::use_data(pred_table)
summary(pred_table)
dim(pred_table)
getwd()
devtools::document()
4+5
devtools::install_github("olicoside/actuarialmetrics")
